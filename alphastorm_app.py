import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
import numpy as np
import pandas as pd
from transformers import AutoTokenizer, AutoModel
import torch
from tqdm import tqdm
import faiss
import streamlit as st
from kiwipiepy import Kiwi
from rank_bm25 import BM25Okapi
import google.generativeai as genai

# ê²½ë¡œ ì„¤ì •
data_path = './data'
module_path = './modules'

# Gemini API í‚¤ë¥¼ st.secretsì—ì„œ ê°€ì ¸ì˜¤ê¸°
gemini_api_key = st.secrets["general"]["gemini_api_key"]

# Gemini API í‚¤ë¡œ ì„¤ì •
genai.configure(api_key=gemini_api_key)
model = genai.GenerativeModel("gemini-1.5-flash")

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
faiss_index_path = os.path.join(module_path, "alphastorm_faiss.index")
document_ids_path = os.path.join(module_path, "alphastorm_documents_ids.npy")
file_path = os.path.join(data_path, 'alphastorm_data.csv')
user_dictionary_path = os.path.join(module_path, 'alphastorm_user_dictionary.txt')  # ì‚¬ìš©ì ì‚¬ì „ íŒŒì¼ ê²½ë¡œ

####------------UI-------------###
# Streamlit App UI
st.set_page_config(layout="wide", page_title="ğŸ½ï¸ì¢€ ìƒ‰ë‹¤ë¥¸ ë§›ì§‘ì„ ì°¾ëŠ”ë‹¤êµ¬? ìš°ë¦¬ê°€ í•´ê²°í•´ì¤„ê²Œ!ğŸ½ï¸")

import streamlit as st

# ------------------------ì „ì²´ ë°°ê²½/ê¸€ê¼´------------------------
st.markdown(
    """
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Jua&display=swap');
    * {
        font-family: 'Jua', sans-serif;
    }

    .stApp {
        background-color: #fdd8b3;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ------------------------íƒ€ì´í‹€------------------------
st.markdown(
    """
    <h1 style='font-family: "Jua", sans-serif;'>ğŸŠ ë‚˜ë§Œì˜ ì œì£¼ë„ ë§›ì§‘ ì—¬í–‰ ğŸŠ</h1>
    """,
    unsafe_allow_html=True
)

# ------------------------ì•± ì†Œê°œ------------------------
with st.expander('ë‹¤ë“¤ ëª¨ë¥´ëŠ” ì œì£¼ë„ ë§›ì§‘, ê¶ê¸ˆí•˜ì§€ ì•Šìœ¼ì„¸ìš”? ğŸ‘€'):
    st.markdown(
    """
    <style>
    .stExpander {
        background-color: #faded0;
        padding: 5px;  /* íŒ¨ë”© ì¶”ê°€ */
        border-radius: 10px;  /* ëª¨ì„œë¦¬ë¥¼ ë‘¥ê¸€ê²Œ */
    }
    </style>
    """,
    unsafe_allow_html=True
    )
    st.markdown(
    """
    <h3 style='font-family: "Jua", sans-serif;'>ë‚¨ë“¤ì€ ì •ë§ ìš´ì´ ì¢‹ì€ ê±¸ê¹Œìš”? ë‚˜ëŠ” ì™œ ë§¤ë²ˆ ì´ë ‡ê²Œ ê¸´ ì›¨ì´íŒ…ì— ì§€ì¹ ê¹Œìš”?</h3>
    """,
    unsafe_allow_html=True
    )
    st.write('ê¸°ëŒ€ê°ì„ ì•ˆê³  ì–´ë µê²Œ í•œ ì… ë§›ë´¤ì§€ë§Œ, ê·¸ì € ê·¸ëŸ° ë§›ì´ì—ˆì„ ë•Œ... ëª¨ë‘ ì´ëŸ¬í•œ ê²½í—˜ì´ ìˆì§€ ì•Šìœ¼ì‹ ê°€ìš”? ğŸ˜¢')
    st.write('ì €í¬ ì•±ì€ ê·¸ëŸ° ì‹¤ë§ìŠ¤ëŸ¬ìš´ ê²½í—˜ ëŒ€ì‹ , **ğŸ’ìˆ¨ê²¨ì§„ ë³´ì„ ê°™ì€ ë§›ì§‘ğŸ’** ì„ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤.')
    st.write('ìœ ëª…í•œ ìŒì‹ì ë“¤ì— ê°€ë ¤ì ¸ ìˆë˜ **ì œì£¼ë„ì˜ ì§„ì§œ ë§›ì§‘**, ê·¸ê³³ì„ ì €í¬ê°€ ì•Œë ¤ë“œë¦´ê²Œìš”! ğŸ½ï¸ğŸ’–')

cols_header = st.columns([6, 1])  # ë¹„ìœ¨ì„ ì„¤ì •í•˜ì—¬ ë ˆì´ë¸”ê³¼ ì´ˆê¸°í™” ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜

with cols_header[0]:  # ì²« ë²ˆì§¸ ì—´ì— ë ˆì´ë¸” í‘œì‹œ
    st.markdown(
        """
        <h4 style='font-family: "Jua", sans-serif;'>ğŸ” ì¥ì†Œì™€ ìŒì‹ ì¢…ë¥˜ë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”!</h4>
        """,
        unsafe_allow_html=True
    )

# ë°ì´í„° ë° ì¸ë±ìŠ¤ ë¡œë“œ
def load_data_and_index():
    if "data_loaded" not in st.session_state:
        # CSV íŒŒì¼ ë¡œë“œ
        data = pd.read_csv(file_path)
        
        # 'complete_document' ì—´ ìƒì„± (ì—¬ëŸ¬ ì—´ì„ ê²°í•©í•˜ì—¬ ë¬¸ì„œ ìƒì„±)
        columns_to_combine = ["ì—…ì¢…ëª…", "ì£¼ì†Œ", "ì´ìš©ê±´ìˆ˜êµ¬ê°„",'ì´ìš©ê¸ˆì•¡êµ¬ê°„', "ìš”ì¼ë³„", "ì‹œê°„ëŒ€ë³„", "ì„±ë³„", "ì—°ë ¹ë³„", "í˜„ì§€ì¸", 'url']
        data['complete_document'] = data[columns_to_combine].apply(lambda row: ' '.join(row.dropna()), axis=1)
        st.session_state.chunk_texts = data['complete_document'].tolist()
        print("complete_document ì—´ ìƒì„± ì™„ë£Œ")
        
        # document_ids ë¡œë“œ
        st.session_state.chunk_document_ids = np.load(document_ids_path, allow_pickle=True).tolist()
        print("Document IDs ë¡œë“œ ì™„ë£Œ")
        
        # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        st.session_state.index = faiss.read_index(faiss_index_path)
        print("FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
        
        # Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸°ì™€ ì‚¬ìš©ì ì‚¬ì „ ë¡œë“œ
        kiwi = Kiwi()
        added_words_count = kiwi.load_user_dictionary(user_dictionary_path)
        print(f"ì‚¬ìš©ì ì •ì˜ ì‚¬ì „ì—ì„œ {added_words_count}ê°œì˜ ë‹¨ì–´ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.session_state.kiwi = kiwi
        
        # BM25ì— ì‚¬ìš©í•  ì½”í¼ìŠ¤ í† í°í™” ë° BM25 ëª¨ë¸ ìƒì„±
        tokenized_corpus = [[token.form for token in kiwi.tokenize(doc)] for doc in st.session_state.chunk_texts]
        st.session_state.bm25 = BM25Okapi(tokenized_corpus)
        print("BM25 ëª¨ë¸ ìƒì„± ì™„ë£Œ")

        # BGE í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ì„¤ì • (CPUì—ì„œ ì‹¤í–‰)
        try:
            st.session_state.tokenizer_bge = AutoTokenizer.from_pretrained("upskyy/bge-m3-korean")
            st.session_state.model_bge = AutoModel.from_pretrained("upskyy/bge-m3-korean")  # GPU ì‚¬ìš© X (CPUì—ì„œ ì‹¤í–‰)
            print("BGE í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            print(f"í† í¬ë‚˜ì´ì € ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        st.session_state.data_loaded = True  # ë°ì´í„°ê°€ ë¡œë“œëœ ìƒíƒœë¡œ í”Œë˜ê·¸ ë³€ê²½
    else:
        print("ë°ì´í„° ë° ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

# BM25 + FAISS ë³‘ë ¬ ê²€ìƒ‰ í•¨ìˆ˜ (ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ë°ì´í„° í™œìš©)
def search_documents(query, bm25_k=500, faiss_k=10):
    # 1. Kiwië¥¼ ì´ìš©í•œ BM25 1ì°¨ ê²€ìƒ‰
    tokenized_query_kiwi = [token.form for token in st.session_state.kiwi.tokenize(query)]
    bm25_results = st.session_state.bm25.get_top_n(tokenized_query_kiwi, st.session_state.chunk_texts, n=bm25_k)
    
    if not bm25_results:
        print("BM25 ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []  # ë¹ˆ ê²°ê³¼ ë°˜í™˜
    
    # 2. BM25 í•„í„°ë§ëœ ë¬¸ì„œë“¤ì˜ document_id ì¶”ì¶œ
    bm25_filtered_ids = [st.session_state.chunk_document_ids[st.session_state.chunk_texts.index(doc)] for doc in bm25_results]
    
    # 3. BGE í† í¬ë‚˜ì´ì €ë¡œ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬)
    query_inputs_bge = st.session_state.tokenizer_bge(query, return_tensors="pt", padding=True, truncation=True)  # CPUì—ì„œ ì‹¤í–‰
    with torch.no_grad():
        query_outputs_bge = st.session_state.model_bge(**query_inputs_bge)
        query_embedding_bge = query_outputs_bge.last_hidden_state.mean(dim=1).numpy()  # GPU ì œê±° (CPUì—ì„œ ì‹¤í–‰)
    
    # 4. FAISS ì¸ë±ìŠ¤ì—ì„œ í•„í„°ë§ëœ ë¬¸ì„œë“¤ì˜ ì„ë² ë”© ê²€ìƒ‰
    faiss.normalize_L2(query_embedding_bge)  # Normalize query embedding for cosine similarity
    
    # FAISS ê²€ìƒ‰ ìˆ˜í–‰
    distances, indices = st.session_state.index.search(query_embedding_bge, faiss_k)
    
    if indices.shape[0] == 0 or indices[0].size == 0:
        print("FAISS ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []  # ë¹ˆ ê²°ê³¼ ë°˜í™˜
    
    print(f"FAISS ê²€ìƒ‰ ì™„ë£Œ - ìƒìœ„ {faiss_k}ê°œì˜ ê²€ìƒ‰ ê²°ê³¼:")
    
    # FAISSì—ì„œ ì°¾ì€ ìƒìœ„ ë¬¸ì„œë“¤ì˜ document_id ì¶”ì¶œ
    retrieved_document_ids = [st.session_state.chunk_document_ids[idx] for idx in indices[0] if idx < len(st.session_state.chunk_document_ids)]
    unique_document_ids = list(dict.fromkeys(retrieved_document_ids))  # ì¤‘ë³µ ì œê±°
    
    if not unique_document_ids:
        print("ë¬¸ì„œ IDê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # ìµœì¢… ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ ë°˜í™˜
    retrieved_documents = [st.session_state.chunk_texts[doc_id] for doc_id in unique_document_ids]
    
    # ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶œë ¥
    for i, doc in enumerate(retrieved_documents, 1):
        print(f"Document {i}: {doc}")

    return retrieved_documents

# LLM(Gemini) ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_gemini_response(query, retrieved_documents):
    # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í”„ë¡¬í”„íŠ¸ë¡œ ê²°í•©
    context = " ".join(retrieved_documents)
    
    # ëª¨ë¸ì— ì „ë‹¬í•  ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = (
    f"As an AI assistant specializing in tourism in Jeju Island, "
    f"please use the following information to respond to the query:\n{context}\n\n"
    
    f"Query: '{query}'\n\n"
    
    # Example 1: ì• ì›”ì—ì„œ 30ëŒ€ ì—¬ì„±ì´ ë§ì´ ê°€ëŠ” ë‹¨í’ˆìš”ë¦¬ ì „ë¬¸ì 
    f"<Example 1>\n"
    f"User asks: 'ì• ì›”ì—ì„œ 30ëŒ€ ì—¬ì„±ì´ ë§ì´ ê°€ëŠ” ë‹¨í’ˆìš”ë¦¬ ì „ë¬¸ì  ì•Œë ¤ì¤˜'\n\n"
    
    f"Search Results (BM25 and FAISS):\n"
    f"Document1: ê°„ì¥ì„ í’ˆì€ ì†Œë¼ê²ŒëŠ” ì• ì›”ìì— ìœ„ì¹˜í•œ ë‹¨í’ˆìš”ë¦¬ ì „ë¬¸ì ì…ë‹ˆë‹¤. "
    f"ì´ìš©ê±´ìˆ˜êµ¬ê°„ì€ 1êµ¬ê°„ìœ¼ë¡œ ì „ì²´ ì´ìš© ê±´ìˆ˜ ì¤‘ í•˜ìœ„ 90%ì— í•´ë‹¹í•©ë‹ˆë‹¤. "
    f"ì—¬ì„± ê³ ê° ë¹„ìœ¨ì´ 52.03%ë¡œ ë” ë†’ê³ , 30ëŒ€ ë°©ë¬¸ê° ë¹„ìœ¨ì€ 28.3%ë¡œ ê°€ì¥ ë§ìŠµë‹ˆë‹¤. "
    f"URL: https://pcmap.place.naver.com/place/1307251244/home\n"
    
    f"Document2: ìš°ë¯¸ë…¸ì‹íƒì€ ì• ì›”ìì— ìœ„ì¹˜í•œ ë‹¨í’ˆìš”ë¦¬ ì „ë¬¸ì ì…ë‹ˆë‹¤. "
    f"ì´ìš©ê±´ìˆ˜êµ¬ê°„ì€ 2êµ¬ê°„ìœ¼ë¡œ ì „ì²´ ì´ìš© ê±´ìˆ˜ ì¤‘ í•˜ìœ„ 75%~90%ì— í•´ë‹¹í•©ë‹ˆë‹¤. "
    f"ì—¬ì„± ê³ ê° ë¹„ìœ¨ì´ 55.39%ë¡œ ë” ë†’ê³ , 30ëŒ€ ë°©ë¬¸ê° ë¹„ìœ¨ì€ 38.32%ë¡œ ê°€ì¥ ë§ìŠµë‹ˆë‹¤. "
    f"URL: https://pcmap.place.naver.com/place/1119656505/home\n"
    
    f"Document3: ì œì£¼ê¸°ì™€ëŠ” ì• ì›”ìì— ìœ„ì¹˜í•œ ë‹¨í’ˆìš”ë¦¬ ì „ë¬¸ì ì…ë‹ˆë‹¤. "
    f"ì´ìš©ê±´ìˆ˜êµ¬ê°„ì€ 3êµ¬ê°„ìœ¼ë¡œ í•˜ìœ„ 50%~75%ì— í•´ë‹¹í•©ë‹ˆë‹¤. "
    f"ì—¬ì„± ê³ ê° ë¹„ìœ¨ì´ 56.70%ë¡œ ë” ë†’ê³ , 30ëŒ€ ë°©ë¬¸ê° ë¹„ìœ¨ì€ 34.6%ë¡œ ê°€ì¥ ë§ìŠµë‹ˆë‹¤. "
    f"URL: https://pcmap.place.naver.com/place/1364855325/home\n\n"
    
    f"Based on these search results:\n"
    
    # í•«í”Œë ˆì´ìŠ¤ ì˜ˆì‹œ
    f"[ğŸ”¥ hot place]:\n"
    f"The first recommendation is 'ê°„ì¥ì„ í’ˆì€ ì†Œë¼ê²Œ'. It is the most popular among women of age thirties, "
    f"with a usage count range of 1 and a high female visitor percentage of 52.03%. "
    f"URL: https://pcmap.place.naver.com/place/1307251244/home\n\n"
    
    # ì½œë“œí”Œë ˆì´ìŠ¤ ì˜ˆì‹œ
    f"[ğŸ’§ cool place]:\n"
    f"A secondary recommendation is 'ì œì£¼ê¸°ì™€', which is less crowded compared to [ğŸ”¥ hot place], "
    f"but still popular among women of age thirties (34.6% female visitors). This makes it a good option for shorter wait times. "
    f"URL: https://pcmap.place.naver.com/place/1364855325/home\n\n"
    
    f"<End of Example 1>\n\n"

    # Example 2: í•œë¦½ìì—ì„œ ì ì‹¬ì— ë§ì´ ê°€ëŠ” ê°€ì •ì‹ì§‘
    f"<Example 2>\n"
    f"User asks: 'í•œë¦½ìì—ì„œ ì ì‹¬ì— ë§ì´ ê°€ëŠ” ê°€ì •ì‹ì§‘ì„ ì•Œë ¤ì¤˜'\n\n"
    
    f"Search Results (BM25 and FAISS):\n"
    f"Document1: ì–‘ë°°ì¶”ì‹ë‹¹ì€ í•œë¦¼ìì— ìœ„ì¹˜í•œ ê°€ì •ì‹ì§‘ì…ë‹ˆë‹¤. "
    f"ì´ìš©ê±´ìˆ˜êµ¬ê°„ì€ 1êµ¬ê°„ìœ¼ë¡œ ì „ì²´ ì´ìš© ê±´ìˆ˜ ì¤‘ í•˜ìœ„ 90%ì— í•´ë‹¹í•©ë‹ˆë‹¤. "
    f"ì ì‹¬ ì‹œê°„(12ì‹œ~13ì‹œ)ì—ëŠ” ì´ìš©ê°ì˜ 95.24%ê°€ ë°©ë¬¸í•˜ë©°, ë‚¨ì„± ê³ ê°ì´ 93.93%ë¡œ ë§ìŠµë‹ˆë‹¤. "
    f"URLì´ ì—†ìŠµë‹ˆë‹¤.\n"
    
    f"Document2: ë°”ë¥´ì™“ì€ í•œë¦¼ìì— ìœ„ì¹˜í•œ ê°€ì •ì‹ì§‘ì…ë‹ˆë‹¤. "
    f"ì´ìš©ê±´ìˆ˜êµ¬ê°„ì€ 2êµ¬ê°„ìœ¼ë¡œ ì „ì²´ ì´ìš© ê±´ìˆ˜ ì¤‘ í•˜ìœ„ 75%~90%ì— í•´ë‹¹í•©ë‹ˆë‹¤. "
    f"ì ì‹¬ ì‹œê°„(12ì‹œ~13ì‹œ)ì—ëŠ” ì´ìš©ê°ì˜ 53.38%ê°€ ë°©ë¬¸í•˜ë©°, ì—¬ì„± ê³ ê° ë¹„ìœ¨ì´ 53.02%ë¡œ ë” ë†’ìŠµë‹ˆë‹¤. "
    f"URL: https://pcmap.place.naver.com/place/1691872277/home\n"
    
    f"Document3: ìƒëª…ì‹ë‹¹ì€ í•œë¦¼ìì— ìœ„ì¹˜í•œ ê°€ì •ì‹ì§‘ì…ë‹ˆë‹¤. "
    f"ì´ìš©ê±´ìˆ˜êµ¬ê°„ì€ 4êµ¬ê°„ìœ¼ë¡œ í•˜ìœ„ 25%~50%ì— í•´ë‹¹í•©ë‹ˆë‹¤. "
    f"ì ì‹¬ ì‹œê°„(12ì‹œ~13ì‹œ)ì—ëŠ” ì´ìš©ê°ì˜ 51.07%ê°€ ë°©ë¬¸í•˜ë©°, ë‚¨ì„± ê³ ê° ë¹„ìœ¨ì´ 65.24%ë¡œ ë” ë§ìŠµë‹ˆë‹¤. "
    f"URL: https://pcmap.place.naver.com/place/1665306171/home\n\n"
    
    f"Based on these search results:\n"
    
    # í•«í”Œë ˆì´ìŠ¤ ì˜ˆì‹œ
    f"[ğŸ”¥ hot place]:\n"
    f"The first recommendation is 'ì–‘ë°°ì¶”ì‹ë‹¹'. It is very popular during lunch time with 95.24% of its visitors coming between 12-1 PM. "
    f"Since it's crowded during lunch, I recommend visiting at other times. No URL is available.\n\n"
    
    # ì½œë“œí”Œë ˆì´ìŠ¤ ì˜ˆì‹œ
    f"[ğŸ’§ cool place]:\n"
    f"A secondary recommendation is 'ë°”ë¥´ì™“', which is less crowded during lunch but still offers a good dining experience. "
    f"This makes it a quieter option compared to 'ì–‘ë°°ì¶”ì‹ë‹¹' which is selected as [ğŸ”¥ hot place]'. "
    f"URL: https://pcmap.place.naver.com/place/1691872277/home\n\n"

    
    f"<End of Example 2>\n\n"

    # Definitions of 'ì´ìš©ê±´ìˆ˜êµ¬ê°„' and 'ì´ìš©ê¸ˆì•¡êµ¬ê°„'
    f"Definitions of 'ì´ìš©ê±´ìˆ˜êµ¬ê°„' and 'ì´ìš©ê¸ˆì•¡êµ¬ê°„':\n\n"
    
    # ì´ìš©ê±´ìˆ˜êµ¬ê°„ ì„¤ëª…
    f"'ì´ìš©ê±´ìˆ˜êµ¬ê°„' (Usage Count Range):\n"
    f"1st range: Lower 90% of usage, Higher 10% and above of usage, very crowded\n"
    f"2nd range: Lower 75%-90% of usage, Higher 10%-25% of usage, normally crowded\n"
    f"3rd range: Lower 50%-75% of usage, Higher 25%-50% of usage\n"
    f"4th range: Lower 25%-50% of usage, Higher 50%-75% of usage, not crowded\n"
    f"5th range: Lower 10%-25% of usage, Higher 75%-90% of usage,not crowded\n"
    f"6th range: Lower 10% and above of usage, Higher 90% of usage, not crowded\n\n"

    # ì´ìš©ê¸ˆì•¡êµ¬ê°„ ì„¤ëª…
    f"'ì´ìš©ê¸ˆì•¡êµ¬ê°„' (Spending Range):\n"
    f"1st range: Lower 90% of usage, Higher 10% and above of usage\n"
    f"2nd range: Lower 75%-90% of usage, Higher 10%-25% of usage\n"
    f"3rd range: Lower 50%-75% of usage, Higher 25%-50% of usage\n"
    f"4th range: Lower 25%-50% of usage, Higher 50%-75% of usage\n"
    f"5th range: Lower 10%-25% of usage, Higher 75%-90% of usagen"
    f"6th range: Lower 10% and above of usage, Higher 90% of usage\n\n"

    f"Note: You must provide [ğŸ”¥hot place] and [ğŸ’§cool place] as an output followed by the general instruction.\n\n"
    
    # í•« í”Œë ˆì´ìŠ¤ ì¶”ì²œ
    f"[ğŸ”¥hot place]:\n\n"
    # f"From the search results, recommend the first place where the majority of visitors are women and age thirties. "
    f"From the search results, recommend the the highest-rated place that satisfies the query: {query}. "
    f"Include the URL directly after the restaurant's description, if available.\n\n"
    
    # ì¿¨ í”Œë ˆì´ìŠ¤ ì¶”ì²œ
    f"[ğŸ’§cool place]:\n\n"
    f"From the given search results, recommend a place with similar characteristics, but less crowded compared to [ğŸ”¥hot place]. "
    f"Explain why it's a quieter or less popular option, based on factors such as time of day, visitor demographics (gender, age), or local resident ratio. "
    f"Make sure to provide reasons why it could be a good alternative to the hot place, such as shorter wait times. "
    f"Include the URL directly after the restaurant's description, if available.\n\n"

    f"Note: The higher the percentage in the 'lower' ranges, the more visitors a place tends to attract.\n\n"
    f"Note: These ranges should be used internally to decide which places to recommend, but do not mention these ranges explicitly in the output.\n\n"
    f"Note: You must answer in korean only.\n\n"
)

    # Gemini ëª¨ë¸ ì´ˆê¸°í™” ë° ì‘ë‹µ ìƒì„±
    gemini_model = genai.GenerativeModel("gemini-1.5-flash")
    response = gemini_model.generate_content(prompt)
    return response.text

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []  # messages ë¦¬ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™”
    
# ë°ì´í„° ë¡œë“œ
load_data_and_index()

# ê¸°ì¡´ ë©”ì‹œì§€ ì¶œë ¥
for message in st.session_state.messages:
    if message["role"] == "user":
        with st.chat_message("user"):
            st.write(message["content"])
    
    if message["role"] == "assistant":
        with st.chat_message("assistant"):
            st.write(message["content"])

# ìƒˆë¡œìš´ ì…ë ¥ì„ ìœ„í•´ í•­ìƒ ì…ë ¥ í•„ë“œë¥¼ ëŒ€í™”ì˜ ë§ˆì§€ë§‰ì— ìœ ì§€
placeholder = st.empty()

with placeholder.form(key=f"chat_form_{len(st.session_state.messages)}"):
        query = st.text_input("ì–´ë””ì„œ ë¬´ì—‡ì„ ë¨¹ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ğŸ¤”", "")
        cols = st.columns([0.012,0.3])
        with cols[0]:
            submit = st.form_submit_button("ì „ì†¡")
        with cols[1]:
            reset = st.form_submit_button("ì²˜ìŒë¶€í„° ë‹¤ì‹œ ğŸ—‘ï¸")
            
        
# ì…ë ¥ì„ ë°›ìœ¼ë©´ ì²˜ë¦¬
if submit and query:
    st.session_state.messages.append({"role": "user", "content": query})

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    with st.chat_message("user"):
        st.write(query)
    
    with st.spinner("ë§›ì§‘ì„ ì°¾ê³  ìˆì–´ìš”! ğŸ§ğŸœğŸ²ğŸ—ğŸ£ğŸ¥¯"):
        retrieved_documents = search_documents(query)
        full_response = generate_gemini_response(query, retrieved_documents)
        
        st.session_state.messages.append({"role": "assistant", "content": full_response})

        with st.chat_message("assistant"):
            st.write(full_response)
            
    # ì…ë ¥ í•„ë“œê°€ ëŒ€í™” ëì— ê³„ì† ìœ ì§€ë¨
    placeholder.empty()  # ì´ì „ í¼ ì‚­ì œ
    with st.form(key=f"chat_form_{len(st.session_state.messages)}"):
        query = st.text_input("ì–´ë””ì„œ ë¬´ì—‡ì„ ë¨¹ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ğŸ¤”", "")
        cols = st.columns([0.012,0.3])
        with cols[0]:
            submit = st.form_submit_button("ì „ì†¡")
        with cols[1]:
            reset = st.form_submit_button("ì²˜ìŒë¶€í„° ë‹¤ì‹œ ğŸ—‘ï¸")

if reset:
    st.session_state.messages = []
    st.session_state["reload"] = True
        